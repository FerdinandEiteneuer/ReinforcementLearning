* in deep_qlearning_agent: functions train,play and _loop into neuralnetwork agent
* in neural_network_agent: analsye_maxQ just assumes states with value 0 are valid and nonzero are not valid.... use env's get_valid_actions?
* visualize training progress
* use propery getter and setter for instead of set_opponent_policy and set_policy?